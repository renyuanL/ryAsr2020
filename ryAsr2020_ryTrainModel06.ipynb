{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Commands: \n",
    "## A Dataset for Limited-Vocabulary Speech Recognition\n",
    "\n",
    "### https://arxiv.org/pdf/1804.03209.pdf\n",
    "\n",
    "#### blog\n",
    "https://petewarden.com/\n",
    "\n",
    "#### Why you need to improve your training data, and how to do it\n",
    "https://petewarden.com/2018/05/28/why-you-need-to-improve-your-training-data-and-how-to-do-it/\n",
    "\n",
    "#### https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md\n",
    "\n",
    "#### TensorFlow Speech Recognition Challenge\n",
    "https://www.kaggle.com/c/tensorflow-speech-recognition-challenge/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The 20 core words are \n",
    "\"Yes\", \"No\", \"Up\", \"Down\", \"Left\", \"Right\", \"On\", \"Off\", \"Stop\", \"Go\", \n",
    "\"Zero\", \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", and \"Nine\". \n",
    "\n",
    "To help distinguish unrecognized words, there are also \n",
    "10 auxiliary words, which most speakers only said once. \n",
    "These include \n",
    "\"Bed\", \"Bird\", \"Cat\", \"Dog\", \"Happy\", \n",
    "\"House\", \"Marvin\", \"Sheila\", \"Tree\", and \"Wow\".\n",
    "\n",
    "add 5 other words in version 2.0\n",
    "\"Forward\", \"Backward\" , \"Learn\", \"Follow\", \"Visual\", \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html\n",
    "\n",
    "Speech Processing for Machine Learning: Filter banks, Mel-Frequency Cepstral Coefficients (MFCCs) and What's In-Between\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#\n",
    "# 讀取 整理過 的資料庫\n",
    "# gscV2_data.npz == 2.96 GB (3,179,793,526 位元組)\n",
    "# 它來自  data_speech_commands_v0.02.tar.gz == 2.26 GB (2,428,923,189 位元組)\n",
    "# 或      train.tar.gz == 2.26 GB (2,428,923,189 位元組)\n",
    "# 但不包含 test.tar.gz ==  107 MB (   112,563,277 位元組)\n",
    "#\n",
    "# 此檔案(gscV2_data.npz) 適合 numpy 讀取，讀取速度相當快。\n",
    "# 它已經根據資料庫原作者建議，\n",
    "# 分成 train(84,843), val (9,981), test(11,005) 3個子集合。\n",
    "# 又從 _background_noise_ 中取出 402 段 1sec 語音，併入 train 中\n",
    "# 因此，讀出的 3個子集合，內含音檔數 分別為... \n",
    "# train(85,245), val (9,981), test(11,005)\n",
    "#\n",
    "# 原資料庫宣稱所有語音當都是 1sec, fs= 16000Hz，\n",
    "# 但事實上有些檔案不及 1sec, 有些又超過 1sec，\n",
    "# 在 gscV2_data.npz 中， 我們有注意到這個問題，並加以解決，\n",
    "# 對於太短的檔案僅是簡單的補0來增長，又把過長檔案的兩端各剪掉一點。\n",
    "# 確定 所有檔案的長度確實為 1sec = 16000點 的語音資料。\n",
    "#\n",
    "# 所有的語音資料的值(x_value)已經轉換成 -1.0 ~ +1.0 的 'float32' 實數\n",
    "# 而其 標籤值(y_value) 為 0 ~ 35 的  'int32' 整數值\n",
    "#     0 代表 _silence_ 或 _background_noise_\n",
    "#     1~35 代表 資料庫之詞彙種類\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basePath= '../ryDatasets/gscV2/'\n",
    "#basePath= '../ryDatasets/tmp/'\n",
    "fn= 'gscV2_data.npz'\n",
    "\n",
    "#\n",
    "# 請來這裡撈這個整理過的檔案：\n",
    "# https://1drv.ms/u/s!AjlltK85sd7q2K1ICtdHw29F_wf3cA?e=wGdOpO\n",
    "# 然後放在 本程式可以讀得到的地方，\n",
    "# 若與本程式同一資料夾，\n",
    "# 則上述 basePath 設定如下: \n",
    "#\n",
    "# basePath= './'     # 代表「目前」的資料夾\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "npzFile= np.load(basePath+fn)\n",
    "\n",
    "\n",
    "x_train=    npzFile['x_trainWithSil']    \n",
    "y_train=    npzFile['y_trainWithSil']    \n",
    "x_val=      npzFile['x_val']      \n",
    "y_val=      npzFile['y_val']\n",
    "x_test=     npzFile['x_test']     \n",
    "y_test=     npzFile['y_test']     \n",
    "\n",
    "\n",
    "## 以後 x_train, y_train, x_val, y_val, x_test, y_test 會用來用去，\n",
    "## 因此先把原始資料存好...\n",
    "\n",
    "x_train_all= x_train\n",
    "y_train_all= y_train\n",
    "\n",
    "x_val_all=   x_val\n",
    "y_val_all=   y_val\n",
    "\n",
    "x_test_all=  x_test\n",
    "y_test_all=  y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 完整的詞彙列表，1 + 35 = 36 個英文詞\n",
    "\n",
    "ryGscList=[ \n",
    " '_silence_',\n",
    " 'one',  'two', 'three', 'four', 'five',\n",
    " 'six', 'seven', 'eight', 'nine', 'zero',\n",
    " 'yes', 'no',\n",
    " 'go', 'stop',\n",
    " 'on', 'off',\n",
    " 'up', 'down',\n",
    " 'left', 'right',\n",
    " 'forward', 'backward',\n",
    " 'marvin', 'sheila',\n",
    " 'dog', 'cat',\n",
    " 'bird', 'bed',\n",
    " 'happy', 'house',\n",
    " 'learn', 'follow',\n",
    " 'tree', 'visual',\n",
    " 'wow'\n",
    " ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 對資料庫做些統計....\n",
    "\n",
    "distTrain= [y_train[y_train==x].size for x in range(len(ryGscList))]\n",
    "distTest=  [y_test[y_test==x].size   for x in range(len(ryGscList))]\n",
    "distVal=   [y_val[y_val==x].size     for x in range(len(ryGscList))]\n",
    "\n",
    "distTrain= np.array(distTrain)\n",
    "distTest=  np.array(distTest)\n",
    "distVal=   np.array(distVal)\n",
    "\n",
    "distAll= distTrain + distTest + distVal\n",
    "\n",
    "aL= list(zip(list(range(len(ryGscList))), \n",
    "             ryGscList,  \n",
    "             list(distAll)))\n",
    "\n",
    "bL= sorted(aL, key= lambda x:x[1])\n",
    "\n",
    "cL= sorted(aL, key= lambda x:-x[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '_silence_', 402),\n",
       " (1, 'one', 3890),\n",
       " (2, 'two', 3880),\n",
       " (3, 'three', 3727),\n",
       " (4, 'four', 3728),\n",
       " (5, 'five', 4052),\n",
       " (6, 'six', 3860),\n",
       " (7, 'seven', 3998),\n",
       " (8, 'eight', 3787),\n",
       " (9, 'nine', 3934),\n",
       " (10, 'zero', 4052),\n",
       " (11, 'yes', 4044),\n",
       " (12, 'no', 3941),\n",
       " (13, 'go', 3880),\n",
       " (14, 'stop', 3872),\n",
       " (15, 'on', 3845),\n",
       " (16, 'off', 3745),\n",
       " (17, 'up', 3723),\n",
       " (18, 'down', 3917),\n",
       " (19, 'left', 3801),\n",
       " (20, 'right', 3778),\n",
       " (21, 'forward', 1557),\n",
       " (22, 'backward', 1664),\n",
       " (23, 'marvin', 2100),\n",
       " (24, 'sheila', 2022),\n",
       " (25, 'dog', 2128),\n",
       " (26, 'cat', 2031),\n",
       " (27, 'bird', 2064),\n",
       " (28, 'bed', 2014),\n",
       " (29, 'happy', 2054),\n",
       " (30, 'house', 2113),\n",
       " (31, 'learn', 1575),\n",
       " (32, 'follow', 1579),\n",
       " (33, 'tree', 1759),\n",
       " (34, 'visual', 1592),\n",
       " (35, 'wow', 2123)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定 3個子集合(Dgt, Yes, Oth)，以及全部(All)。\n",
    "\n",
    "#  Dgt= 10 個數字\n",
    "CmdList= DgtList=  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "# Yes= 10 個 Cmd，    「是、否、去、停、 開、關、上、下、  左、右」。\n",
    "CmdList= YesList=  [0, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "\n",
    "# 其他 15 個。\n",
    "CmdList= OthList= [ 0, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]\n",
    "\n",
    "# 總共 10 + 10 + 15 == 35\n",
    "CmdList= AllList= list(range(0,36))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 選好 CmdList 即可完整跑到底....\n",
    "# Dgt 辨識率最高，可先選來做做看\n",
    "\n",
    "#CmdList= DgtList\n",
    "#CmdList= YesList\n",
    "#CmdList= OthList\n",
    "CmdList= AllList\n",
    "\n",
    "CmdList= np.array(CmdList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 選擇 子集合來建立 模型\n",
    "\n",
    "s_trainCmd= np.isin(y_train_all, CmdList)\n",
    "s_valCmd=   np.isin(y_val_all,   CmdList)\n",
    "s_testCmd=  np.isin(y_test_all,  CmdList)\n",
    "\n",
    "x_trainCmd= x_train_all[s_trainCmd]\n",
    "y_trainCmd= y_train_all[s_trainCmd]\n",
    "\n",
    "x_valCmd=   x_val_all[s_valCmd]\n",
    "y_valCmd=   y_val_all[s_valCmd]\n",
    "\n",
    "x_testCmd=  x_test_all[s_testCmd]\n",
    "y_testCmd=  y_test_all[s_testCmd]\n",
    "\n",
    "# 把 label 從 0, 1, 2,... 降到 0, 1, 2,....\n",
    "# 對 Dgt 子集合而言，不做沒關係，但 Yes, Oth 都必須做，因此一視同仁通通做吧。\n",
    "#\n",
    "CmdDict= dict([(v,k) for k,v in enumerate(CmdList)])\n",
    "\n",
    "y_train= np.array([CmdDict[x] for x in y_trainCmd])\n",
    "y_val=   np.array([CmdDict[x] for x in y_valCmd])\n",
    "y_test=  np.array([CmdDict[x] for x in y_testCmd])\n",
    "\n",
    "\n",
    "# 選擇 語音資料子集合來建立 模型\n",
    "\n",
    "x_train=    x_trainCmd    \n",
    "x_val=      x_valCmd\n",
    "x_test=     x_testCmd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nCategs= 36\n"
     ]
    }
   ],
   "source": [
    "# 檢查一下 類別總數 (nCaters)，\n",
    "# Dgt= 11, Yes=11, Oth=16, All=36\n",
    "#\n",
    "\n",
    "nCategs= len(set(y_train)) #36 #c_train.size #36\n",
    "\n",
    "print(f'nCategs= {nCategs}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 重要演算法 開始囉....\n",
    "\n",
    "def ryFeature(x, \n",
    "           sample_rate= 16000, \n",
    "           \n",
    "           frame_length=  256, #1024,\n",
    "           frame_step=    160, #128,  # frame_length//2\n",
    "           \n",
    "           num_mel_bins=     256//8, #32, #100,   #128,\n",
    "           lower_edge_hertz=   0,     # 0\n",
    "           upper_edge_hertz= 16000/2, # sample_rate/2   \n",
    "           \n",
    "           mfcc_dim= 16 #13\n",
    "           ):\n",
    "    \n",
    "    stfts= tf.signal.stft(x, \n",
    "                          frame_length, #=  256, #1024, \n",
    "                          frame_step, #=    128,\n",
    "                          #fft_length= 1024\n",
    "                          pad_end=True\n",
    "                          )\n",
    "    \n",
    "    spectrograms=     tf.abs(stfts)\n",
    "    log_spectrograms= tf.math.log(spectrograms)# + 1e-10)\n",
    "    \n",
    "    # Warp the linear scale spectrograms into the mel-scale.\n",
    "    num_spectrogram_bins= stfts.shape[-1]  #.value\n",
    "    \n",
    "    \n",
    "    linear_to_mel_weight_matrix= tf.signal.linear_to_mel_weight_matrix(\n",
    "          num_mel_bins, \n",
    "          num_spectrogram_bins, \n",
    "          sample_rate, \n",
    "          lower_edge_hertz,\n",
    "          upper_edge_hertz)\n",
    "    \n",
    "    '''\n",
    "    mel_spectrograms= tf.tensordot(\n",
    "          spectrograms, \n",
    "          linear_to_mel_weight_matrix, 1)\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    W= linear_to_mel_weight_matrix\n",
    "      \n",
    "    W1= W/ tf.math.reduce_sum(W, axis=0)  # 我把 那些 三角形濾波器 sum to one 了。\n",
    "    \n",
    "    mel_spectrograms= spectrograms @ W1  # 這行取代 tensordot()\n",
    "    \n",
    "    # 以下這行似乎無作用\n",
    "    '''\n",
    "    mel_spectrograms.set_shape(\n",
    "          spectrograms.shape[:-1].concatenate(\n",
    "              linear_to_mel_weight_matrix.shape[-1:]))\n",
    "    '''\n",
    "    \n",
    "    # Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n",
    "    log_mel_spectrograms= tf.math.log(mel_spectrograms + 1e-10) # 加上 1e-10 避免 log(0) 的出現\n",
    "    \n",
    "    # Compute MFCCs from log_mel_spectrograms and take the first 13.\n",
    "    mfccs= tf.signal.mfccs_from_log_mel_spectrograms(\n",
    "          log_mel_spectrograms)[..., :mfcc_dim]\n",
    "    \n",
    "    feature= {'mfcc':               mfccs, \n",
    "              'log_mel_spectrogram':log_mel_spectrograms, \n",
    "              \n",
    "              'log_spectrogram':    log_spectrograms,  # 以下 2個 不太有用，留下僅供參考。\n",
    "              'spectrogram':        spectrograms}\n",
    "    \n",
    "    return  feature\n",
    "\n",
    "def get_all_fearure(all_x, batch_size= 1000):\n",
    "    t0= time.time()\n",
    "    \n",
    "    x= all_x.astype(np.float32)\n",
    "    \n",
    "    #batch_size= 1000  # 預防 gpu memory 不夠， 分批作業 \n",
    "    \n",
    "    i=0\n",
    "    XL=[]\n",
    "    while i < x.shape[0]:\n",
    "        \n",
    "        if i+batch_size<=x.shape[0]:\n",
    "            xx= x[i:i+batch_size]\n",
    "        else:\n",
    "            xx= x[i:]\n",
    "        \n",
    "        X= ryFeature(xx)['mfcc']\n",
    "        \n",
    "        '''\n",
    "        X0256= ryFeature(xx, frame_length= 256, num_mel_bins= 256//8)['mfcc']      \n",
    "        X1024= ryFeature(xx, frame_length=1024, num_mel_bins=1024//8)['mfcc']\n",
    "        X= tf.concat([X0256, X1024], axis=-1)\n",
    "        '''\n",
    "        \n",
    "        i  += batch_size\n",
    "        XL += [X]\n",
    "    \n",
    "    #XL= np.concatenate(XL)\n",
    "    XL= tf.concat(XL, axis= 0)\n",
    "    print('XL.shape={}'.format(XL.shape))\n",
    "    \n",
    "    dt= time.time()-t0\n",
    "    print('tf.signal.stft, 執行時間 dt= {}'.format(dt))\n",
    "    \n",
    "    '''\n",
    "    XL.shape=(64721, 125, 129) # nTime= 16000/128, nFreq=256/2+1\n",
    "    tf.signal.stft, dt= 8.066392660140991\n",
    "    '''\n",
    "    return XL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".... get_all_fearure() .... \n",
      "XL.shape=(11005, 100, 16)\n",
      "tf.signal.stft, 執行時間 dt= 2.7040350437164307\n",
      "XL.shape=(9981, 100, 16)\n",
      "tf.signal.stft, 執行時間 dt= 0.6256437301635742\n",
      "XL.shape=(85245, 100, 16)\n",
      "tf.signal.stft, 執行時間 dt= 5.741328477859497\n",
      "... get_all_fearure() ... dt(sec)= 9.529\n"
     ]
    }
   ],
   "source": [
    "print('.... get_all_fearure() .... ')\n",
    "\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "t0= time.time()\n",
    "\n",
    "X_test=     get_all_fearure(x_test)\n",
    "X_val=      get_all_fearure(x_val)\n",
    "X_train=    get_all_fearure(x_train)\n",
    "\n",
    "dt= time.time()- t0\n",
    "print('... get_all_fearure() ... dt(sec)= {:.3f}'.format(dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 檢查 X_train 的 形狀\n",
    "nTime, nFreq= X_train[0].shape\n",
    "nTime, nFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".... normalize() ....\n"
     ]
    }
   ],
   "source": [
    "# 要對 X_* 們作 正規化\n",
    "\n",
    "def normalize(x, axis= None):   \n",
    "    if axis== None:\n",
    "        #x= (x-x.mean())/x.std()\n",
    "        x= (x - tf.math.reduce_mean(x)\n",
    "            )/tf.math.reduce_std(x)\n",
    "    else:\n",
    "        #x= (x-x.mean(axis= axis))/x.std(axis= axis)\n",
    "        x= (x - tf.math.reduce_mean(x, axis)\n",
    "            )/tf.math.reduce_std(x, axis)\n",
    "    \n",
    "    return x\n",
    "\n",
    "print('.... normalize() ....')\n",
    "\n",
    "X_train= tf.reshape(X_train, (-1, nTime, nFreq ,1))\n",
    "X_val=   tf.reshape(X_val,   (-1, nTime, nFreq ,1))\n",
    "X_test=  tf.reshape(X_test,  (-1, nTime, nFreq ,1))\n",
    "\n",
    "X_train=     normalize(X_train) \n",
    "X_val=       normalize(X_val)   \n",
    "X_test=      normalize(X_test)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=32342, shape=(), dtype=float32, numpy=2.6706684e-09>,\n",
       " <tf.Tensor: id=32349, shape=(), dtype=float32, numpy=0.99999994>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 檢查一下，mean 應為 0, std 應為 1\n",
    "tf.math.reduce_mean(X_train), tf.math.reduce_std(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以上先把語音資料庫處理完畢，並作了 特徵擷取 (mfcc)\n",
    "# 接著要進入 cnn + dnn 神經網路 建模了....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models    import Model, load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... fnModel= ryAsr2020_ryTrainModel.hdf5\n"
     ]
    }
   ],
   "source": [
    "# 啟動 tf.keras\n",
    "tf.keras.backend.clear_session()  \n",
    "\n",
    "# 準備好模型的檔名以便訓練時儲存。\n",
    "fnModel= 'ryAsr2020_ryTrainModel.hdf5'\n",
    "print(f\"... fnModel= {fnModel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  開始設立 CNN 模型，盡量簡單為要。。。\n",
    "# 【Simple is Beautiful】\n",
    "#  \n",
    "def ryCnn(nTime, nFreq, nCategories):\n",
    "    \n",
    "    x= Input(shape= (nTime, nFreq, 1))\n",
    "    \n",
    "    h= x      \n",
    "    h= Conv2D(10,   (10, nFreq), \n",
    "              activation='relu', \n",
    "              padding='same', \n",
    "              strides=(2, nFreq)\n",
    "              )(h)    \n",
    "    h= MaxPooling2D((2,1), padding='same')(h)    \n",
    "    h= Dropout(0.1)(h)\n",
    "           \n",
    "    h= Flatten()(h)\n",
    "    h= Dense(100,  activation='relu')(h)  \n",
    "    h= Dropout(0.1)(h)      \n",
    "    h= Dense(nCategs,  activation='softmax')(h)    \n",
    "    y= h\n",
    "    \n",
    "    m= Model(inputs=  x, \n",
    "             outputs= y)    \n",
    "    m.summary()\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100, 16, 1)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 50, 1, 10)         1610      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 25, 1, 10)         0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25, 1, 10)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               25100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 36)                3636      \n",
      "=================================================================\n",
      "Total params: 30,346\n",
      "Trainable params: 30,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m= ryCnn(nTime, nFreq,  nCategories= nCategs) \n",
    "    \n",
    "m.compile(  \n",
    "        loss=    'sparse_categorical_crossentropy',\n",
    "        metrics= ['accuracy'])\n",
    "\n",
    "es= EarlyStopping(\n",
    "        monitor=   'val_loss', \n",
    "        min_delta= 1e-10,\n",
    "        patience=  10, \n",
    "        mode=      'min', \n",
    "        verbose=   1) \n",
    "\n",
    "mc= ModelCheckpoint(fnModel, \n",
    "        monitor=    'val_accuracy', \n",
    "        verbose=    1, \n",
    "        save_best_only= True, \n",
    "        mode=      'max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 85245 samples, validate on 9981 samples\n",
      "Epoch 1/100\n",
      "85000/85245 [============================>.] - ETA: 0s - loss: 2.5179 - accuracy: 0.2966\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.52099, saving model to ryAsr2020_ryTrainModel.hdf5\n",
      "85245/85245 [==============================] - 3s 40us/sample - loss: 2.5159 - accuracy: 0.2971 - val_loss: 1.7561 - val_accuracy: 0.5210\n",
      "Epoch 2/100\n",
      "84600/85245 [============================>.] - ETA: 0s - loss: 1.6429 - accuracy: 0.5259\n",
      "Epoch 00002: val_accuracy improved from 0.52099 to 0.64703, saving model to ryAsr2020_ryTrainModel.hdf5\n",
      "85245/85245 [==============================] - 2s 26us/sample - loss: 1.6422 - accuracy: 0.5262 - val_loss: 1.2532 - val_accuracy: 0.6470\n",
      "Epoch 3/100\n",
      "85000/85245 [============================>.] - ETA: 0s - loss: 1.3630 - accuracy: 0.6012\n",
      "Epoch 00003: val_accuracy improved from 0.64703 to 0.68951, saving model to ryAsr2020_ryTrainModel.hdf5\n",
      "85245/85245 [==============================] - 2s 25us/sample - loss: 1.3630 - accuracy: 0.6012 - val_loss: 1.0768 - val_accuracy: 0.6895\n",
      "Epoch 4/100\n",
      "84800/85245 [============================>.] - ETA: 0s - loss: 1.2195 - accuracy: 0.6408\n",
      "Epoch 00004: val_accuracy improved from 0.68951 to 0.72127, saving model to ryAsr2020_ryTrainModel.hdf5\n",
      "85245/85245 [==============================] - 2s 27us/sample - loss: 1.2194 - accuracy: 0.6408 - val_loss: 0.9747 - val_accuracy: 0.7213\n",
      "Epoch 5/100\n",
      "82900/85245 [============================>.] - ETA: 0s - loss: 1.1396 - accuracy: 0.6635\n",
      "Epoch 00005: val_accuracy improved from 0.72127 to 0.73680, saving model to ryAsr2020_ryTrainModel.hdf5\n",
      "85245/85245 [==============================] - 2s 26us/sample - loss: 1.1386 - accuracy: 0.6639 - val_loss: 0.9101 - val_accuracy: 0.7368\n",
      "Epoch 6/100\n",
      "83800/85245 [============================>.] - ETA: 0s - loss: 1.0781 - accuracy: 0.6785\n",
      "Epoch 00006: val_accuracy improved from 0.73680 to 0.75043, saving model to ryAsr2020_ryTrainModel.hdf5\n",
      "85245/85245 [==============================] - 2s 26us/sample - loss: 1.0777 - accuracy: 0.6786 - val_loss: 0.8684 - val_accuracy: 0.7504\n",
      "Epoch 7/100\n",
      "83700/85245 [============================>.] - ETA: 0s - loss: 1.0316 - accuracy: 0.6930\n",
      "Epoch 00007: val_accuracy improved from 0.75043 to 0.75924, saving model to ryAsr2020_ryTrainModel.hdf5\n",
      "85245/85245 [==============================] - 2s 26us/sample - loss: 1.0304 - accuracy: 0.6934 - val_loss: 0.8343 - val_accuracy: 0.7592\n",
      "Epoch 8/100\n",
      "85200/85245 [============================>.] - ETA: 0s - loss: 1.0002 - accuracy: 0.7051\n",
      "Epoch 00008: val_accuracy improved from 0.75924 to 0.76385, saving model to ryAsr2020_ryTrainModel.hdf5\n",
      "85245/85245 [==============================] - 2s 26us/sample - loss: 1.0000 - accuracy: 0.7052 - val_loss: 0.8105 - val_accuracy: 0.7639\n",
      "Epoch 9/100\n",
      "83800/85245 [============================>.] - ETA: 0s - loss: 0.9676 - accuracy: 0.7112\n",
      "Epoch 00009: val_accuracy improved from 0.76385 to 0.77527, saving model to ryAsr2020_ryTrainModel.hdf5\n",
      "85245/85245 [==============================] - 2s 27us/sample - loss: 0.9668 - accuracy: 0.7114 - val_loss: 0.7906 - val_accuracy: 0.7753\n",
      "Epoch 10/100\n",
      "84000/85245 [============================>.] - ETA: 0s - loss: 0.9422 - accuracy: 0.7177\n",
      "Epoch 00010: val_accuracy improved from 0.77527 to 0.78098, saving model to ryAsr2020_ryTrainModel.hdf5\n",
      "85245/85245 [==============================] - 2s 26us/sample - loss: 0.9415 - accuracy: 0.7180 - val_loss: 0.7580 - val_accuracy: 0.7810\n",
      "Epoch 11/100\n",
      "84400/85245 [============================>.] - ETA: 0s - loss: 0.9192 - accuracy: 0.7259\n",
      "Epoch 00011: val_accuracy improved from 0.78098 to 0.78389, saving model to ryAsr2020_ryTrainModel.hdf5\n",
      "85245/85245 [==============================] - 2s 26us/sample - loss: 0.9185 - accuracy: 0.7260 - val_loss: 0.7482 - val_accuracy: 0.7839\n",
      "Epoch 12/100\n",
      "84000/85245 [============================>.] - ETA: 0s - loss: 0.9031 - accuracy: 0.7294\n",
      "Epoch 00012: val_accuracy did not improve from 0.78389\n",
      "85245/85245 [==============================] - 2s 26us/sample - loss: 0.9033 - accuracy: 0.7293 - val_loss: 0.7586 - val_accuracy: 0.7790\n",
      "Epoch 13/100\n",
      "84900/85245 [============================>.] - ETA: 0s - loss: 0.8868 - accuracy: 0.7357\n",
      "Epoch 00013: val_accuracy improved from 0.78389 to 0.78840, saving model to ryAsr2020_ryTrainModel.hdf5\n",
      "85245/85245 [==============================] - 2s 25us/sample - loss: 0.8869 - accuracy: 0.7357 - val_loss: 0.7333 - val_accuracy: 0.7884\n",
      "Epoch 14/100\n",
      "83700/85245 [============================>.] - ETA: 0s - loss: 0.8690 - accuracy: 0.7385\n",
      "Epoch 00014: val_accuracy improved from 0.78840 to 0.79110, saving model to ryAsr2020_ryTrainModel.hdf5\n",
      "85245/85245 [==============================] - 2s 26us/sample - loss: 0.8688 - accuracy: 0.7386 - val_loss: 0.7187 - val_accuracy: 0.7911\n",
      "Epoch 15/100\n",
      "83400/85245 [============================>.] - ETA: 0s - loss: 0.8594 - accuracy: 0.7440\n",
      "Epoch 00015: val_accuracy improved from 0.79110 to 0.79311, saving model to ryAsr2020_ryTrainModel.hdf5\n",
      "85245/85245 [==============================] - 2s 26us/sample - loss: 0.8600 - accuracy: 0.7434 - val_loss: 0.7062 - val_accuracy: 0.7931\n",
      "Epoch 16/100\n",
      "84500/85245 [============================>.] - ETA: 0s - loss: 0.8468 - accuracy: 0.7448\n",
      "Epoch 00016: val_accuracy did not improve from 0.79311\n",
      "85245/85245 [==============================] - 2s 25us/sample - loss: 0.8467 - accuracy: 0.7449 - val_loss: 0.7345 - val_accuracy: 0.7899\n",
      "Epoch 17/100\n",
      "83100/85245 [============================>.] - ETA: 0s - loss: 0.8380 - accuracy: 0.7496\n",
      "Epoch 00017: val_accuracy did not improve from 0.79311\n",
      "85245/85245 [==============================] - 2s 25us/sample - loss: 0.8384 - accuracy: 0.7493 - val_loss: 0.7171 - val_accuracy: 0.7924\n",
      "Epoch 18/100\n",
      "85200/85245 [============================>.] - ETA: 0s - loss: 0.8278 - accuracy: 0.7517\n",
      "Epoch 00018: val_accuracy improved from 0.79311 to 0.79711, saving model to ryAsr2020_ryTrainModel.hdf5\n",
      "85245/85245 [==============================] - 2s 25us/sample - loss: 0.8279 - accuracy: 0.7517 - val_loss: 0.7011 - val_accuracy: 0.7971\n",
      "Epoch 19/100\n",
      "83300/85245 [============================>.] - ETA: 0s - loss: 0.8232 - accuracy: 0.7551\n",
      "Epoch 00019: val_accuracy did not improve from 0.79711\n",
      "85245/85245 [==============================] - 2s 26us/sample - loss: 0.8241 - accuracy: 0.7550 - val_loss: 0.7139 - val_accuracy: 0.7933\n",
      "Epoch 20/100\n",
      "84300/85245 [============================>.] - ETA: 0s - loss: 0.8171 - accuracy: 0.7548\n",
      "Epoch 00020: val_accuracy did not improve from 0.79711\n",
      "85245/85245 [==============================] - 2s 25us/sample - loss: 0.8168 - accuracy: 0.7549 - val_loss: 0.7001 - val_accuracy: 0.7964\n",
      "Epoch 21/100\n",
      "83200/85245 [============================>.] - ETA: 0s - loss: 0.8103 - accuracy: 0.7554\n",
      "Epoch 00021: val_accuracy improved from 0.79711 to 0.80132, saving model to ryAsr2020_ryTrainModel.hdf5\n",
      "85245/85245 [==============================] - 2s 26us/sample - loss: 0.8095 - accuracy: 0.7555 - val_loss: 0.6775 - val_accuracy: 0.8013\n",
      "Epoch 22/100\n",
      "84800/85245 [============================>.] - ETA: 0s - loss: 0.8056 - accuracy: 0.7590\n",
      "Epoch 00022: val_accuracy improved from 0.80132 to 0.80353, saving model to ryAsr2020_ryTrainModel.hdf5\n",
      "85245/85245 [==============================] - 2s 28us/sample - loss: 0.8054 - accuracy: 0.7590 - val_loss: 0.6951 - val_accuracy: 0.8035\n",
      "Epoch 23/100\n",
      "84600/85245 [============================>.] - ETA: 0s - loss: 0.7960 - accuracy: 0.7610\n",
      "Epoch 00023: val_accuracy improved from 0.80353 to 0.80533, saving model to ryAsr2020_ryTrainModel.hdf5\n",
      "85245/85245 [==============================] - 2s 29us/sample - loss: 0.7952 - accuracy: 0.7612 - val_loss: 0.6876 - val_accuracy: 0.8053\n",
      "Epoch 24/100\n",
      "83800/85245 [============================>.] - ETA: 0s - loss: 0.7939 - accuracy: 0.7633\n",
      "Epoch 00024: val_accuracy did not improve from 0.80533\n",
      "85245/85245 [==============================] - 2s 27us/sample - loss: 0.7941 - accuracy: 0.7632 - val_loss: 0.6747 - val_accuracy: 0.8042\n",
      "Epoch 25/100\n",
      "83900/85245 [============================>.] - ETA: 0s - loss: 0.7870 - accuracy: 0.7643\n",
      "Epoch 00025: val_accuracy improved from 0.80533 to 0.80904, saving model to ryAsr2020_ryTrainModel.hdf5\n",
      "85245/85245 [==============================] - 2s 27us/sample - loss: 0.7870 - accuracy: 0.7639 - val_loss: 0.6665 - val_accuracy: 0.8090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "84800/85245 [============================>.] - ETA: 0s - loss: 0.7827 - accuracy: 0.7658\n",
      "Epoch 00026: val_accuracy did not improve from 0.80904\n",
      "85245/85245 [==============================] - 2s 26us/sample - loss: 0.7829 - accuracy: 0.7658 - val_loss: 0.7117 - val_accuracy: 0.7960\n",
      "Epoch 27/100\n",
      "84900/85245 [============================>.] - ETA: 0s - loss: 0.7796 - accuracy: 0.7653\n",
      "Epoch 00027: val_accuracy did not improve from 0.80904\n",
      "85245/85245 [==============================] - 2s 26us/sample - loss: 0.7802 - accuracy: 0.7652 - val_loss: 0.6891 - val_accuracy: 0.8080\n",
      "Epoch 28/100\n",
      "84000/85245 [============================>.] - ETA: 0s - loss: 0.7750 - accuracy: 0.7688\n",
      "Epoch 00028: val_accuracy improved from 0.80904 to 0.80964, saving model to ryAsr2020_ryTrainModel.hdf5\n",
      "85245/85245 [==============================] - 2s 28us/sample - loss: 0.7757 - accuracy: 0.7686 - val_loss: 0.6647 - val_accuracy: 0.8096\n",
      "Epoch 29/100\n",
      "83900/85245 [============================>.] - ETA: 0s - loss: 0.7734 - accuracy: 0.7683\n",
      "Epoch 00029: val_accuracy did not improve from 0.80964\n",
      "85245/85245 [==============================] - 2s 26us/sample - loss: 0.7726 - accuracy: 0.7685 - val_loss: 0.6971 - val_accuracy: 0.8024\n",
      "Epoch 30/100\n",
      "85200/85245 [============================>.] - ETA: 0s - loss: 0.7701 - accuracy: 0.7683\n",
      "Epoch 00030: val_accuracy improved from 0.80964 to 0.81274, saving model to ryAsr2020_ryTrainModel.hdf5\n",
      "85245/85245 [==============================] - 2s 28us/sample - loss: 0.7700 - accuracy: 0.7684 - val_loss: 0.6621 - val_accuracy: 0.8127\n",
      "Epoch 31/100\n",
      "84000/85245 [============================>.] - ETA: 0s - loss: 0.7709 - accuracy: 0.7699\n",
      "Epoch 00031: val_accuracy did not improve from 0.81274\n",
      "85245/85245 [==============================] - 2s 27us/sample - loss: 0.7716 - accuracy: 0.7697 - val_loss: 0.6646 - val_accuracy: 0.8060\n",
      "Epoch 32/100\n",
      "83600/85245 [============================>.] - ETA: 0s - loss: 0.7580 - accuracy: 0.7733\n",
      "Epoch 00032: val_accuracy did not improve from 0.81274\n",
      "85245/85245 [==============================] - 2s 26us/sample - loss: 0.7575 - accuracy: 0.7735 - val_loss: 0.6597 - val_accuracy: 0.8097\n",
      "Epoch 33/100\n",
      "83600/85245 [============================>.] - ETA: 0s - loss: 0.7648 - accuracy: 0.7692\n",
      "Epoch 00033: val_accuracy did not improve from 0.81274\n",
      "85245/85245 [==============================] - 2s 26us/sample - loss: 0.7643 - accuracy: 0.7695 - val_loss: 0.6740 - val_accuracy: 0.8047\n",
      "Epoch 34/100\n",
      "83900/85245 [============================>.] - ETA: 0s - loss: 0.7584 - accuracy: 0.7717\n",
      "Epoch 00034: val_accuracy did not improve from 0.81274\n",
      "85245/85245 [==============================] - 2s 26us/sample - loss: 0.7591 - accuracy: 0.7715 - val_loss: 0.6663 - val_accuracy: 0.8105\n",
      "Epoch 35/100\n",
      "84400/85245 [============================>.] - ETA: 0s - loss: 0.7572 - accuracy: 0.7736\n",
      "Epoch 00035: val_accuracy did not improve from 0.81274\n",
      "85245/85245 [==============================] - 2s 26us/sample - loss: 0.7569 - accuracy: 0.7737 - val_loss: 0.6996 - val_accuracy: 0.8019\n",
      "Epoch 36/100\n",
      "83500/85245 [============================>.] - ETA: 0s - loss: 0.7576 - accuracy: 0.7746\n",
      "Epoch 00036: val_accuracy did not improve from 0.81274\n",
      "85245/85245 [==============================] - 2s 26us/sample - loss: 0.7577 - accuracy: 0.7745 - val_loss: 0.6718 - val_accuracy: 0.8073\n",
      "Epoch 37/100\n",
      "84500/85245 [============================>.] - ETA: 0s - loss: 0.7517 - accuracy: 0.7761\n",
      "Epoch 00037: val_accuracy did not improve from 0.81274\n",
      "85245/85245 [==============================] - 2s 25us/sample - loss: 0.7521 - accuracy: 0.7759 - val_loss: 0.6724 - val_accuracy: 0.8101\n",
      "Epoch 38/100\n",
      "84600/85245 [============================>.] - ETA: 0s - loss: 0.7527 - accuracy: 0.7734\n",
      "Epoch 00038: val_accuracy did not improve from 0.81274\n",
      "85245/85245 [==============================] - 2s 27us/sample - loss: 0.7530 - accuracy: 0.7732 - val_loss: 0.6751 - val_accuracy: 0.8037\n",
      "Epoch 39/100\n",
      "84600/85245 [============================>.] - ETA: 0s - loss: 0.7490 - accuracy: 0.7761\n",
      "Epoch 00039: val_accuracy did not improve from 0.81274\n",
      "85245/85245 [==============================] - 2s 27us/sample - loss: 0.7485 - accuracy: 0.7762 - val_loss: 0.6731 - val_accuracy: 0.8108\n",
      "Epoch 40/100\n",
      "84100/85245 [============================>.] - ETA: 0s - loss: 0.7476 - accuracy: 0.7776\n",
      "Epoch 00040: val_accuracy did not improve from 0.81274\n",
      "85245/85245 [==============================] - 2s 28us/sample - loss: 0.7471 - accuracy: 0.7777 - val_loss: 0.7150 - val_accuracy: 0.8027\n",
      "Epoch 41/100\n",
      "84000/85245 [============================>.] - ETA: 0s - loss: 0.7448 - accuracy: 0.7775\n",
      "Epoch 00041: val_accuracy did not improve from 0.81274\n",
      "85245/85245 [==============================] - 2s 26us/sample - loss: 0.7453 - accuracy: 0.7772 - val_loss: 0.6737 - val_accuracy: 0.8077\n",
      "Epoch 42/100\n",
      "84500/85245 [============================>.] - ETA: 0s - loss: 0.7493 - accuracy: 0.7776\n",
      "Epoch 00042: val_accuracy did not improve from 0.81274\n",
      "85245/85245 [==============================] - 2s 25us/sample - loss: 0.7489 - accuracy: 0.7777 - val_loss: 0.6775 - val_accuracy: 0.8078\n",
      "Epoch 00042: early stopping\n",
      "... h= m.fit() ... dt(sec)= 95.36719369888306\n"
     ]
    }
   ],
   "source": [
    "### 要正式跑【模型訓練】了\n",
    "\n",
    "# 通常會很久，故 監視一下時間 ...\n",
    "t0= time.time() \n",
    "\n",
    "h= m.fit(X_train, y_train,\n",
    "         \n",
    "        batch_size=100, #1000, # 1000\n",
    "        epochs=    100,\n",
    "        \n",
    "        callbacks=[es, mc],\n",
    "        \n",
    "        #validation_split= 0.1\n",
    "        validation_data= (X_val, y_val)\n",
    "        )\n",
    "\n",
    "dt= time.time()- t0\n",
    "print('... h= m.fit() ... dt(sec)= {}'.format(dt))\n",
    "\n",
    "## 紀錄一下 我在 家中電腦 跑的結果以資參考...\n",
    "\n",
    "_=''' 桌機上跑的結果 (with GPU, Nvidia 1080Ti)\n",
    "Epoch 60/100\n",
    "31000/31560 [============================>.] - ETA: 0s - loss: 0.1614 - accuracy: 0.9465\n",
    "Epoch 00060: 【val_accuracy】 did not improve from 【0.94236】\n",
    "31560/31560 [==============================] - 1s 25us/sample - loss: 0.1618 - accuracy: 0.9465 - val_loss: 0.2368 - val_accuracy: 0.9380\n",
    "Epoch 00060: early stopping\n",
    "... h= 【m.fit()】 ... dt(sec)= 【54.17984127998352】(約 1 min)\n",
    "\n",
    "'''\n",
    "\n",
    "_=''' 筆電上跑的結果 (without GPU), for subset Dgt (10 個英文數字詞) \n",
    "Epoch 00049: 【val_accuracy】 did not improve from 【0.93769】\n",
    "31560/31560 [==============================] - 13s 400us/sample - loss: 0.1808 - accuracy: 0.9416 - val_loss: 0.2403 - val_accuracy: 0.9325\n",
    "Epoch 00049: early stopping\n",
    "... h= 【m.fit()】 ... dt(sec)= 【595.3162362575531】(約 10 min)\n",
    "'''\n",
    "\n",
    "_=''' 筆電(CPU= 8, RAM= 8G, without Nvidia GPU)上跑的結果 , for All (35 英文詞) \n",
    "Epoch 00052: val_accuracy did not improve from 【0.81745】\n",
    "85245/85245 [==============================] - 32s 377us/sample - loss: 0.7613 - accuracy: 0.7752 - val_loss: 0.6583 - val_accuracy: 0.8159\n",
    "Epoch 00052: early stopping\n",
    "... h= 【m.fit()】 ... dt(sec)= 【1896.6248784065247】 (約 30 min)\n",
    "'''\n",
    "\n",
    "_=''' 桌機，for All (35 英文詞)\n",
    "Epoch 00042: val_accuracy did not improve from 0.81274\n",
    "85245/85245 [==============================] - 2s 25us/sample - loss: 0.7489 - accuracy: 0.7777 - val_loss: 0.6775 - val_accuracy: 0.8078\n",
    "Epoch 00042: early stopping\n",
    "... h= m.fit() ... dt(sec)= 【95.36719369888306】 (約 1.5 min， 約是無GPU筆電的20倍速度。)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11005/1 - 0s - loss: 0.7127 - accuracy: 0.8070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.681186114799321, 0.8069968]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最後再跑個 測試辨識率\n",
    "m.evaluate(X_test,      y_test,      verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sortPred= ['tree' 'three' 'eight' 'two' 'six' 'happy' 'sheila' 'seven' 'bird' 'zero'\n",
      " 'right' 'bed' 'visual' 'go' 'four' 'five' 'nine' 'cat' 'stop' 'yes'\n",
      " 'left' 'learn' 'forward' 'down' 'marvin' 'one' 'follow' 'dog' 'no' 'up'\n",
      " 'house' 'on' 'backward' 'off' 'wow' '_silence_']\n",
      "sortProb= [9.0568674e-01 9.4293833e-02 1.9089339e-05 3.2677056e-07 3.8888821e-08\n",
      " 3.7549682e-08 5.7117444e-09 3.3060445e-09 7.2959871e-10 6.8103173e-10\n",
      " 4.7722837e-10 5.0886791e-11 1.3780893e-11 4.5019907e-13 3.3657951e-13\n",
      " 2.4912575e-13 6.9946077e-14 6.0115399e-14 2.2986540e-14 4.7134537e-15\n",
      " 3.1815540e-15 1.2269587e-15 2.4659522e-16 5.6507791e-17 1.6607224e-17\n",
      " 7.4065562e-18 3.7950108e-18 3.5245434e-18 2.7606055e-18 1.8082051e-19\n",
      " 1.1975421e-19 1.7601494e-20 4.9149225e-22 1.2020851e-22 4.5162330e-28\n",
      " 4.9337289e-36]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "import sounddevice as sd\n",
    "\n",
    "#  找 1 個 語音來測試\n",
    "randomIndex= 1000\n",
    "\n",
    "x= x_test[randomIndex]\n",
    "X= X_test[randomIndex]\n",
    "\n",
    "X=    tf.reshape(X, (1, X.shape[0], X.shape[1], 1))\n",
    "prob= m.predict(X)[0]\n",
    "\n",
    "sortIndex=  prob.argsort()[-1::-1]\n",
    "sortProb=   prob[sortIndex]\n",
    "\n",
    "sortPred=    np.array(ryGscList)[CmdList[sortIndex]] ## 這行有點錯綜複雜！！\n",
    "\n",
    "print(f'sortPred= {sortPred}') # topN recognition result\n",
    "print(f'sortProb= {sortProb}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.contour.QuadContourSet at 0x1aad668e148>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the data\n",
    "\n",
    "sd.play(x, 16000)\n",
    "\n",
    "pl.subplot(2,1,1);pl.grid('on');pl.plot(x)\n",
    "\n",
    "X= X.numpy().squeeze().transpose()\n",
    "pl.subplot(2,1,2);pl.grid('on');pl.contourf(X)#, levels=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 畫個 訓練過程 acc 變化的圖形...\n",
    "\n",
    "from matplotlib import pyplot as pl\n",
    "\n",
    "def plot_train_history(h):\n",
    "    v0= h.history['accuracy']\n",
    "    v1= h.history['val_accuracy']\n",
    "    pl.plot(v0, label='accuracy')\n",
    "    pl.plot(v1, label='val_accuracy')\n",
    "    pl.legend()\n",
    "    pl.grid('on')\n",
    "    pl.show()\n",
    "\n",
    "plot_train_history(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最後，作個實作系統來玩玩...\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import sounddevice as sd\n",
    "\n",
    "labels= np.array(ryGscList)\n",
    "\n",
    "fnModel= 'ryAsr2020_ryTrainModel.hdf5'\n",
    "\n",
    "model= load_model(fnModel)\n",
    "\n",
    "\n",
    "def predict(x, probOut= False, indexMapping= None):\n",
    "    \n",
    "    x= tf.reshape(x, (1, x.shape[0], x.shape[1], 1))\n",
    "    \n",
    "    prob=  model.predict(x)\n",
    "    index= np.argmax(prob[0])\n",
    "    maxProb= np.max(prob[0])\n",
    "    \n",
    "    if indexMapping != None:\n",
    "        index= indexMapping[index]\n",
    "        \n",
    "    y= labels[index]\n",
    "    \n",
    "    if probOut==True:\n",
    "        return (y, maxProb)\n",
    "    else:\n",
    "        return y\n",
    "\n",
    "\n",
    "def recWav(x, probOut= False): #, indexMapping= None):\n",
    "    \n",
    "    x= x.flatten()    \n",
    "\n",
    "    X= ryFeature(x)['mfcc']\n",
    "        \n",
    "    X= normalize(X)  # normalized for only one utterence x\n",
    "\n",
    "    #y= predict(X, probOut= probOut, indexMapping= indexMapping)\n",
    "    \n",
    "    X= tf.reshape(X, (1, X.shape[0], X.shape[1], 1))\n",
    "    \n",
    "    prob=  model.predict(X)[0]\n",
    "    index=   prob.argsort()[-1::-1]#np.argmax(prob)\n",
    "    maxProb= prob[index] #np.max(prob)\n",
    "    \n",
    "    #if indexMapping != None:\n",
    "    #    index= indexMapping[index]\n",
    "    index= CmdList[index]    \n",
    "    \n",
    "    y= labels[index]\n",
    "    \n",
    "    if probOut==True:\n",
    "        y= np.vstack((y, maxProb))\n",
    "    return y\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    press a key to record 1 sec of speech ...\n",
      "    you can say: ['_silence_' 'one' 'two' 'three' 'four' 'five' 'six' 'seven' 'eight'\n",
      " 'nine' 'zero' 'yes' 'no' 'go' 'stop' 'on' 'off' 'up' 'down' 'left'\n",
      " 'right' 'forward' 'backward' 'marvin' 'sheila' 'dog' 'cat' 'bird' 'bed'\n",
      " 'happy' 'house' 'learn' 'follow' 'tree' 'visual' 'wow']\n",
      "    please say it within 1 sec...\n",
      "    \n",
      "\n",
      "y= [['one' 'on' 'wow' 'learn' 'marvin' 'nine' 'four' 'left' 'right'\n",
      "  'forward' 'five' 'down' 'off' 'follow' 'bird' 'backward' 'dog' 'no'\n",
      "  'up' 'go' 'bed' 'seven' 'stop' 'two' 'three' 'happy' 'yes' 'zero'\n",
      "  'sheila' 'eight' 'visual' 'house' 'cat' 'tree' 'six' '_silence_']\n",
      " ['0.9231221' '0.03340952' '0.018456668' '0.0068795285' '0.0058341995'\n",
      "  '0.0041867713' '0.0031400563' '0.0009404039' '0.0008454047'\n",
      "  '0.00078824285' '0.0006847419' '0.00033731008' '0.0003289102'\n",
      "  '0.00016894595' '0.00016616592' '0.00016160958' '0.0001433213'\n",
      "  '0.00011402297' '0.000111382906' '0.00010048912' '1.8377628e-05'\n",
      "  '1.7433671e-05' '1.6764454e-05' '8.348381e-06' '8.090865e-06'\n",
      "  '3.2007238e-06' '2.897736e-06' '1.7426081e-06' '1.3809324e-06'\n",
      "  '8.4285836e-07' '8.247717e-07' '1.6984811e-07' '1.11658615e-07'\n",
      "  '3.4328046e-08' '1.580171e-08' '6.451047e-16']]\n",
      "\n",
      "    press a key to record 1 sec of speech ...\n",
      "    you can say: ['_silence_' 'one' 'two' 'three' 'four' 'five' 'six' 'seven' 'eight'\n",
      " 'nine' 'zero' 'yes' 'no' 'go' 'stop' 'on' 'off' 'up' 'down' 'left'\n",
      " 'right' 'forward' 'backward' 'marvin' 'sheila' 'dog' 'cat' 'bird' 'bed'\n",
      " 'happy' 'house' 'learn' 'follow' 'tree' 'visual' 'wow']\n",
      "    please say it within 1 sec...\n",
      "    \n",
      "\n",
      "y= [['two' 'sheila' 'tree' 'four' 'go' 'three' 'zero' 'visual' 'eight'\n",
      "  'stop' 'forward' 'seven' 'happy' 'six' 'follow' 'dog' 'up' 'down' 'on'\n",
      "  'cat' 'bed' 'five' 'no' 'off' 'yes' 'one' 'wow' 'bird' 'nine'\n",
      "  'backward' 'left' 'learn' 'right' 'marvin' 'house' '_silence_']\n",
      " ['0.5834888' '0.10953' '0.07847737' '0.03307597' '0.02921272'\n",
      "  '0.02841584' '0.023417406' '0.020624146' '0.01797296' '0.017100383'\n",
      "  '0.010913052' '0.0075397594' '0.006137186' '0.0061015873'\n",
      "  '0.0059918463' '0.005692525' '0.0028951308' '0.0023949004'\n",
      "  '0.0019507778' '0.0018809013' '0.0017048414' '0.0014140778'\n",
      "  '0.0009588362' '0.00093899487' '0.000494967' '0.00032994652'\n",
      "  '0.0002831353' '0.0002213511' '0.00019369603' '0.0001704348'\n",
      "  '0.00014442544' '0.00010933603' '0.00010701095' '7.732743e-05'\n",
      "  '3.829168e-05' '1.5938828e-09']]\n",
      "\n",
      "    press a key to record 1 sec of speech ...\n",
      "    you can say: ['_silence_' 'one' 'two' 'three' 'four' 'five' 'six' 'seven' 'eight'\n",
      " 'nine' 'zero' 'yes' 'no' 'go' 'stop' 'on' 'off' 'up' 'down' 'left'\n",
      " 'right' 'forward' 'backward' 'marvin' 'sheila' 'dog' 'cat' 'bird' 'bed'\n",
      " 'happy' 'house' 'learn' 'follow' 'tree' 'visual' 'wow']\n",
      "    please say it within 1 sec...\n",
      "    \n",
      "\n",
      "y= [['two' 'tree' 'three' 'sheila' 'seven' 'six' 'zero' 'happy' 'stop'\n",
      "  'eight' 'visual' 'five' 'go' 'cat' 'yes' 'down' 'right' 'four' 'nine'\n",
      "  'bird' 'bed' 'left' 'up' 'on' 'one' 'marvin' 'forward' 'no' 'off'\n",
      "  'learn' 'follow' 'dog' 'house' 'backward' 'wow' '_silence_']\n",
      " ['0.39766985' '0.3702264' '0.12975451' '0.043660767' '0.02448054'\n",
      "  '0.008800875' '0.008612973' '0.006491699' '0.004149998' '0.0025572272'\n",
      "  '0.0009786895' '0.0006848689' '0.00034868837' '0.00034417605'\n",
      "  '0.00030430313' '0.00029388836' '0.00013935282' '0.00013391362'\n",
      "  '0.0001135377' '6.0802726e-05' '3.7934085e-05' '3.3965196e-05'\n",
      "  '2.6478578e-05' '2.2526789e-05' '1.5727554e-05' '1.44622845e-05'\n",
      "  '9.12983e-06' '9.092553e-06' '8.49667e-06' '6.015545e-06'\n",
      "  '4.3495106e-06' '3.5847156e-06' '6.508807e-07' '3.3943275e-07'\n",
      "  '1.7913104e-07' '2.1029583e-14']]\n",
      "\n",
      "    press a key to record 1 sec of speech ...\n",
      "    you can say: ['_silence_' 'one' 'two' 'three' 'four' 'five' 'six' 'seven' 'eight'\n",
      " 'nine' 'zero' 'yes' 'no' 'go' 'stop' 'on' 'off' 'up' 'down' 'left'\n",
      " 'right' 'forward' 'backward' 'marvin' 'sheila' 'dog' 'cat' 'bird' 'bed'\n",
      " 'happy' 'house' 'learn' 'follow' 'tree' 'visual' 'wow']\n",
      "    please say it within 1 sec...\n",
      "    \n",
      "\n",
      "y= [['forward' 'four' 'on' 'follow' 'five' 'three' 'seven' 'two' 'dog' 'go'\n",
      "  'tree' 'one' 'bird' 'right' 'stop' 'off' 'down' 'learn' 'marvin' 'zero'\n",
      "  'happy' 'backward' 'visual' 'up' 'house' 'six' 'left' 'nine' 'wow' 'no'\n",
      "  'eight' 'bed' 'cat' 'sheila' 'yes' '_silence_']\n",
      " ['0.49238253' '0.26173142' '0.13306703' '0.04243168' '0.025281502'\n",
      "  '0.021205392' '0.005048436' '0.004694947' '0.0041931635' '0.0029646093'\n",
      "  '0.0016029697' '0.001303864' '0.0010463941' '0.00064267823'\n",
      "  '0.00062171347' '0.0003362225' '0.0003248231' '0.00017790215'\n",
      "  '0.00016229844' '0.0001408173' '0.00012934454' '0.00011215035'\n",
      "  '8.720262e-05' '8.4939704e-05' '4.9860384e-05' '3.9929066e-05'\n",
      "  '3.487741e-05' '2.5412866e-05' '2.447827e-05' '2.0323178e-05'\n",
      "  '1.7566317e-05' '6.274273e-06' '3.8455896e-06' '2.1253857e-06'\n",
      "  '1.2549622e-06' '8.662054e-14']]\n",
      "\n",
      "    press a key to record 1 sec of speech ...\n",
      "    you can say: ['_silence_' 'one' 'two' 'three' 'four' 'five' 'six' 'seven' 'eight'\n",
      " 'nine' 'zero' 'yes' 'no' 'go' 'stop' 'on' 'off' 'up' 'down' 'left'\n",
      " 'right' 'forward' 'backward' 'marvin' 'sheila' 'dog' 'cat' 'bird' 'bed'\n",
      " 'happy' 'house' 'learn' 'follow' 'tree' 'visual' 'wow']\n",
      "    please say it within 1 sec...\n",
      "    \n",
      "\n",
      "y= [['five' 'on' 'up' 'off' 'right' 'stop' 'cat' 'one' 'three' 'happy'\n",
      "  'four' 'tree' 'nine' 'dog' 'forward' 'seven' 'left' 'eight' 'wow'\n",
      "  'house' 'down' 'bed' 'follow' 'marvin' 'six' 'two' 'sheila' 'backward'\n",
      "  'go' 'bird' 'visual' 'learn' 'yes' 'no' 'zero' '_silence_']\n",
      " ['0.7759326' '0.17292637' '0.015098384' '0.010265182' '0.0059507056'\n",
      "  '0.005931' '0.0041046888' '0.0030441557' '0.0017019426' '0.0015295302'\n",
      "  '0.0011142362' '0.00045896016' '0.00041960197' '0.00033327992'\n",
      "  '0.0002930663' '0.00024547445' '0.0001564777' '0.00014387412'\n",
      "  '9.094352e-05' '4.913273e-05' '4.637619e-05' '4.5064808e-05'\n",
      "  '3.1966643e-05' '2.2969882e-05' '2.2534627e-05' '1.7685303e-05'\n",
      "  '1.1972548e-05' '4.271419e-06' '2.2897955e-06' '1.7313549e-06'\n",
      "  '1.4830009e-06' '9.355007e-07' '5.6957197e-07' '4.2513008e-07'\n",
      "  '1.2848821e-07' '2.5642102e-13']]\n",
      "\n",
      "    press a key to record 1 sec of speech ...\n",
      "    you can say: ['_silence_' 'one' 'two' 'three' 'four' 'five' 'six' 'seven' 'eight'\n",
      " 'nine' 'zero' 'yes' 'no' 'go' 'stop' 'on' 'off' 'up' 'down' 'left'\n",
      " 'right' 'forward' 'backward' 'marvin' 'sheila' 'dog' 'cat' 'bird' 'bed'\n",
      " 'happy' 'house' 'learn' 'follow' 'tree' 'visual' 'wow']\n",
      "    please say it within 1 sec...\n",
      "    \n",
      "\n",
      "y= [['six' 'stop' 'off' 'sheila' 'yes' 'left' 'cat' 'house' 'four' 'three'\n",
      "  'eight' 'zero' 'five' 'seven' 'right' 'two' 'dog' 'tree' 'visual' 'go'\n",
      "  'forward' 'up' 'bird' '_silence_' 'down' 'happy' 'no' 'bed' 'follow'\n",
      "  'on' 'one' 'backward' 'marvin' 'nine' 'learn' 'wow']\n",
      " ['0.9903656' '0.0031740346' '0.0017368376' '0.001555953' '0.0011194183'\n",
      "  '0.00056828343' '0.00043826184' '0.00032848094' '0.00021033529'\n",
      "  '0.00013444934' '0.000100733625' '5.2447744e-05' '4.0627467e-05'\n",
      "  '3.7370424e-05' '3.0119987e-05' '2.965562e-05' '2.8809189e-05'\n",
      "  '2.1778194e-05' '1.0539807e-05' '9.042004e-06' '4.4533117e-06'\n",
      "  '1.7454661e-06' '2.5587548e-07' '2.1338052e-07' '1.8374703e-07'\n",
      "  '1.06338945e-07' '6.301888e-08' '3.1908407e-08' '2.1832644e-08'\n",
      "  '1.9345231e-08' '1.7744263e-08' '9.539868e-09' '3.3265022e-09'\n",
      "  '1.0547307e-09' '1.0822455e-10' '9.614057e-11']]\n",
      "\n",
      "    press a key to record 1 sec of speech ...\n",
      "    you can say: ['_silence_' 'one' 'two' 'three' 'four' 'five' 'six' 'seven' 'eight'\n",
      " 'nine' 'zero' 'yes' 'no' 'go' 'stop' 'on' 'off' 'up' 'down' 'left'\n",
      " 'right' 'forward' 'backward' 'marvin' 'sheila' 'dog' 'cat' 'bird' 'bed'\n",
      " 'happy' 'house' 'learn' 'follow' 'tree' 'visual' 'wow']\n",
      "    please say it within 1 sec...\n",
      "    \n",
      "\n",
      "y= [['seven' 'stop' 'zero' 'two' 'three' 'sheila' 'down' 'six' 'tree' 'four'\n",
      "  'five' 'go' 'bird' 'learn' 'cat' 'on' 'up' 'dog' 'visual' 'forward'\n",
      "  'nine' 'one' 'marvin' 'happy' 'bed' 'yes' 'left' 'no' 'backward'\n",
      "  'right' 'follow' 'off' 'house' 'eight' 'wow' '_silence_']\n",
      " ['0.87835324' '0.035969023' '0.027153589' '0.026560469' '0.008320738'\n",
      "  '0.007063483' '0.0062681604' '0.0053554215' '0.0012647012'\n",
      "  '0.0009410229' '0.0009268614' '0.00043974904' '0.00037450728'\n",
      "  '0.00029192198' '0.00018219784' '8.750606e-05' '8.277025e-05'\n",
      "  '7.877112e-05' '6.346603e-05' '4.9584043e-05' '4.682379e-05'\n",
      "  '1.825731e-05' '1.7456137e-05' '1.6159445e-05' '1.6159323e-05'\n",
      "  '1.47196015e-05' '1.1094887e-05' '1.085047e-05' '7.583537e-06'\n",
      "  '6.7551728e-06' '2.5274562e-06' '1.8951592e-06' '1.4909931e-06'\n",
      "  '1.0864277e-06' '6.273885e-08' '3.124766e-15']]\n",
      "\n",
      "    press a key to record 1 sec of speech ...\n",
      "    you can say: ['_silence_' 'one' 'two' 'three' 'four' 'five' 'six' 'seven' 'eight'\n",
      " 'nine' 'zero' 'yes' 'no' 'go' 'stop' 'on' 'off' 'up' 'down' 'left'\n",
      " 'right' 'forward' 'backward' 'marvin' 'sheila' 'dog' 'cat' 'bird' 'bed'\n",
      " 'happy' 'house' 'learn' 'follow' 'tree' 'visual' 'wow']\n",
      "    please say it within 1 sec...\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y= [['eight' 'two' 'three' 'tree' 'six' 'yes' 'happy' 'sheila' 'visual'\n",
      "  'bed' 'right' 'five' 'nine' 'zero' 'go' 'one' 'left' 'cat' 'down'\n",
      "  'bird' 'no' 'seven' 'learn' 'four' 'marvin' 'on' 'dog' 'follow' 'stop'\n",
      "  'forward' 'off' 'house' 'wow' 'up' 'backward' '_silence_']\n",
      " ['0.77086186' '0.110127605' '0.034620058' '0.01370834' '0.012516093'\n",
      "  '0.011225389' '0.010508053' '0.006854624' '0.004859831' '0.0046505164'\n",
      "  '0.0039541926' '0.0029388932' '0.0027143871' '0.0026336506'\n",
      "  '0.001802234' '0.0015248287' '0.00089430186' '0.00066635176'\n",
      "  '0.00043757964' '0.00041578984' '0.0003759473' '0.00036273376'\n",
      "  '0.00030246266' '0.00027943737' '0.00018978964' '0.00017376425'\n",
      "  '0.00014047508' '0.0001313216' '5.21931e-05' '2.7229325e-05'\n",
      "  '2.1180389e-05' '1.4948527e-05' '5.8946766e-06' '4.7166727e-06'\n",
      "  '3.271284e-06' '7.933117e-13']]\n",
      "\n",
      "    press a key to record 1 sec of speech ...\n",
      "    you can say: ['_silence_' 'one' 'two' 'three' 'four' 'five' 'six' 'seven' 'eight'\n",
      " 'nine' 'zero' 'yes' 'no' 'go' 'stop' 'on' 'off' 'up' 'down' 'left'\n",
      " 'right' 'forward' 'backward' 'marvin' 'sheila' 'dog' 'cat' 'bird' 'bed'\n",
      " 'happy' 'house' 'learn' 'follow' 'tree' 'visual' 'wow']\n",
      "    please say it within 1 sec...\n",
      "    \n",
      "\n",
      "y= [['nine' 'marvin' 'backward' 'down' 'dog' 'one' 'learn' 'happy' 'bird'\n",
      "  'bed' 'no' 'right' 'wow' 'five' 'go' 'on' 'three' 'seven' 'left' 'up'\n",
      "  'two' 'zero' 'visual' 'eight' 'tree' 'follow' 'four' 'sheila' 'forward'\n",
      "  'cat' 'stop' 'yes' 'off' 'house' 'six' '_silence_']\n",
      " ['0.5026353' '0.22253335' '0.039625615' '0.038704183' '0.034197647'\n",
      "  '0.03194452' '0.028003346' '0.015204565' '0.014314854' '0.012513962'\n",
      "  '0.011995544' '0.011822033' '0.007898775' '0.0053103496' '0.0052926643'\n",
      "  '0.0052568223' '0.0024545079' '0.0017825024' '0.0017438846'\n",
      "  '0.0015795846' '0.0012337746' '0.00092848804' '0.00079174584'\n",
      "  '0.00049687905' '0.00036886096' '0.00032703963' '0.00031819948'\n",
      "  '0.00024390129' '0.00015123679' '0.00011394243' '8.0559075e-05'\n",
      "  '6.2283776e-05' '5.2623447e-05' '9.8457995e-06' '6.5572403e-06'\n",
      "  '1.2268059e-13']]\n",
      "\n",
      "    press a key to record 1 sec of speech ...\n",
      "    you can say: ['_silence_' 'one' 'two' 'three' 'four' 'five' 'six' 'seven' 'eight'\n",
      " 'nine' 'zero' 'yes' 'no' 'go' 'stop' 'on' 'off' 'up' 'down' 'left'\n",
      " 'right' 'forward' 'backward' 'marvin' 'sheila' 'dog' 'cat' 'bird' 'bed'\n",
      " 'happy' 'house' 'learn' 'follow' 'tree' 'visual' 'wow']\n",
      "    please say it within 1 sec...\n",
      "    \n",
      "\n",
      "y= [['yes' 'six' 'eight' 'left' 'visual' 'sheila' 'right' 'down' 'cat' 'no'\n",
      "  'zero' 'go' 'stop' 'one' 'two' 'four' 'dog' 'three' 'nine' 'bed'\n",
      "  'house' 'five' 'happy' 'seven' 'learn' 'backward' 'tree' 'off' 'bird'\n",
      "  'marvin' 'forward' 'follow' 'up' 'wow' 'on' '_silence_']\n",
      " ['0.9948072' '0.0024469148' '0.0018734328' '0.0007948152'\n",
      "  '3.3115757e-05' '1.061095e-05' '9.400566e-06' '5.4170628e-06'\n",
      "  '4.8127454e-06' '3.2629075e-06' '3.0224542e-06' '1.5064289e-06'\n",
      "  '1.3536189e-06' '8.059274e-07' '7.751533e-07' '7.533477e-07'\n",
      "  '7.470576e-07' '7.1676834e-07' '2.844394e-07' '2.630795e-07'\n",
      "  '2.562257e-07' '1.9220747e-07' '8.3111665e-08' '5.6791286e-08'\n",
      "  '5.4666295e-08' '3.3927925e-08' '1.5475317e-08' '1.12198695e-08'\n",
      "  '5.1590803e-09' '4.1340202e-09' '2.6072444e-09' '5.2702726e-10'\n",
      "  '7.0551995e-11' '4.0136488e-11' '2.8775989e-11' '7.081946e-19']]\n"
     ]
    }
   ],
   "source": [
    "T=  1     # Duration of recording\n",
    "fs= 16000  # Sample rate\n",
    "def speak_and_recognize():\n",
    "    print(f'''\n",
    "    press a key to record 1 sec of speech ...\n",
    "    you can say: {labels[CmdList]}\n",
    "    please say it within 1 sec...\n",
    "    ''')\n",
    "    input() \n",
    "    x= sd.rec(int(T*fs), \n",
    "            samplerate= fs, \n",
    "            channels= 1, \n",
    "            dtype='float32')\n",
    "\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "\n",
    "    y= recWav(x, probOut=True)#, indexMapping= CmdList) \n",
    "\n",
    "    print('y= {}'.format(y))\n",
    "\n",
    "for i in range(10):\n",
    "    speak_and_recognize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... ry: Good Luck for you in 2020 ...\n"
     ]
    }
   ],
   "source": [
    "print('... ry: Good Luck for you in 2020 ...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
